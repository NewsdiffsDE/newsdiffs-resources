{\rtf1\ansi\ansicpg1252\cocoartf1344\cocoasubrtf720
{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720

\f0\fs24 \cf0 \expnd0\expndtw0\kerning0
Also einen Zaubertrick gibt es nicht. Sondern das ist Detektivarbeit. Wie sehr spezifisch du das angehen sollst, l\'e4sst sich schwer definieren. "Scraper schreiben in Datenbank" m\'fcsste nicht weiter aufgedr\'f6selt werden. Aber mir fallen andere konkrete Fragen ein: - Ist der Scraping-Intervall pro Zeitung festgelegt, oder global?\
\
- Wer st\'f6\'dft die Scraper an? Ist das ein Cronjob? \
entered while true schleife in kommandozeile, die all 60 min left ODER lesser: cronjob: script dass zu bestimmten uhrzeiten funktion aufruft\
\
- Wie besuchen die Scraper die Seiten? Erst die Titelseite und direkt darauf alle gefundenen verlinkten Seiten? Oder werden alle Titelseiten in einer Liste gespeichert und dann nach eigenem Intervall abgearbeitet?\
ja. zeit.de/news/index -> zeit.de/news, alle urls mit diesem muster werden \'fcbernommen\
\
- Die Scraper bei Moreno hatten auch auf die Festplatte geschrieben, nicht nur in die Datenbank. Was hat das auf sich?\
f\'fcr jedentag werden Artikel (txt) unter articles gespeichert, nur die \'c4nderungen (!) werden in der db abgespeichert\
\
- Wo und wie wird der diff gemacht? Schon beim Scrapen? Oder erst beim Besuch der Seite? Wird das Diff in der Datenbank gemacht, oder mit Textdateien auf der Festplatte? In welcher Form wird der Diff gespeichert? Und wo?\
\
}